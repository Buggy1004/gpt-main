{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "import requests\n",
    "import tiktoken\n",
    "\n",
    "def read_url(url: str) -> str:\n",
    "    response: requests.Response = requests.get(url)\n",
    "    text: str = response.content.decode(\"utf-8\")\n",
    "    return text\n",
    "\n",
    "def read_file(path: str) -> str:\n",
    "    with open(path, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()\n",
    "\n",
    "def faust(url: str) -> str:\n",
    "    text: str = read_url(url)\n",
    "    lines: list[str] = text.splitlines()\n",
    "    return \"\\n\".join(lines[69:7184])\n",
    "\n",
    "def _ratio(text: str, encoding_name: str) -> float:\n",
    "    encoding: tiktoken.Encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens: int = len(encoding.encode(text))\n",
    "    num_chars: int = len(text)\n",
    "    return num_chars / num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "* p50k_base: In German, each token represents 2.25 characters.\n",
      "* cl100k_base: In German, each token represents 3.10 characters.\n",
      "Improvement over old encoding: 0.85\n",
      "---\n",
      "* p50k_base: In English, each token represents 3.30 characters.\n",
      "* cl100k_base: In English, each token represents 3.70 characters.\n",
      "Improvement over old encoding: 0.40\n",
      "---\n",
      "* p50k_base: In Python, each token represents 3.07 characters.\n",
      "* cl100k_base: In Python, each token represents 3.63 characters.\n",
      "Improvement over old encoding: 0.56\n",
      "---\n",
      "* p50k_base: In C, each token represents 2.97 characters.\n",
      "* cl100k_base: In C, each token represents 3.56 characters.\n",
      "Improvement over old encoding: 0.59\n",
      "---\n",
      "* p50k_base: In C-Plus-Plus, each token represents 3.10 characters.\n",
      "* cl100k_base: In C-Plus-Plus, each token represents 3.68 characters.\n",
      "Improvement over old encoding: 0.57\n",
      "---\n",
      "* p50k_base: In JavaScript, each token represents 2.94 characters.\n",
      "* cl100k_base: In JavaScript, each token represents 3.35 characters.\n",
      "Improvement over old encoding: 0.41\n",
      "---\n",
      "* p50k_base: In Go, each token represents 2.42 characters.\n",
      "* cl100k_base: In Go, each token represents 3.03 characters.\n",
      "Improvement over old encoding: 0.61\n",
      "---\n",
      "* p50k_base: In Java, each token represents 3.33 characters.\n",
      "* cl100k_base: In Java, each token represents 4.01 characters.\n",
      "Improvement over old encoding: 0.68\n"
     ]
    }
   ],
   "source": [
    "# In this analysis, we calculate the character-to-token ratio for several languages.\n",
    "# For the programming languages, the repositories from the GitHub project https://github.com/TheAlgorithms were used.\n",
    "# Using merge_files.py, we combined the code into a single file for each programming.\n",
    "# As per the definition provided by VG Wort, a standard page consists of 1,500 characters.\n",
    "# https://www.vgwort.de/auszahlungen/wissenschaftliche-publikationen/fach-und-sachzeitschriften.html\n",
    "\n",
    "data: list[tuple[str, Callable, str]] = [\n",
    "    (\"German\", faust, \"https://www.gutenberg.org/files/2229/2229-0.txt\"),\n",
    "    (\"English\", read_url, \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"),\n",
    "    (\"Python\", read_file, os.path.join(\"playground\", \"data\", \"py.txt\")),\n",
    "    (\"C\", read_file, os.path.join(\"playground\", \"data\", \"c.txt\")),\n",
    "    (\"C-Plus-Plus\", read_file, os.path.join(\"playground\", \"data\", \"cpp.txt\")),\n",
    "    (\"JavaScript\", read_file, os.path.join(\"playground\", \"data\", \"js.txt\")),\n",
    "    (\"Go\", read_file, os.path.join(\"playground\", \"data\", \"go.txt\")),\n",
    "    (\"Java\", read_file, os.path.join(\"playground\", \"data\", \"java.txt\"))\n",
    "]\n",
    "\n",
    "ENCODING_P50K_BASE: str = \"p50k_base\"\n",
    "ENCODING_CL100K_BASE: str = \"cl100k_base\"\n",
    "\n",
    "for element in data:\n",
    "    language, func, url = element\n",
    "    text: str = func(url)\n",
    "    ratio_50: float = _ratio(text, ENCODING_P50K_BASE)\n",
    "    ratio_100: float = _ratio(text, ENCODING_CL100K_BASE)\n",
    "    print(\"---\")\n",
    "    print(f\"* {ENCODING_P50K_BASE}: In {language}, each token represents {ratio_50:.2f} characters. A standard page contains {1500 / ratio_50:.0f} tokens.\")\n",
    "    print(f\"* {ENCODING_CL100K_BASE}: In {language}, each token represents {ratio_100:.2f} characters. A standard page contains {1500 / ratio_100:.0f} tokens.\")\n",
    "    print(f\"Improvement over old encoding: {(ratio_100 - ratio_50):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
